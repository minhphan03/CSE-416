{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 1. Setting Up\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "from nltk import ConditionalFreqDist\n",
                "from sklearn.cluster import KMeans\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 2. Loading the Dataset"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We will be analyzing the dataset of the inaugural speeches by US presidents. Let's explore the dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import nltk\n",
                "nltk.download(\"inaugural\")\n",
                "\n",
                "from nltk.corpus import inaugural"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "raw_data = []\n",
                "for fileid in inaugural.fileids():\n",
                "    raw_data.append([fileid, \" \".join(inaugural.words(fileid))])\n",
                "data = pd.DataFrame(raw_data, columns=[\"File ID\", \"Text\"])\n",
                "data"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 2. Vectorize the Text\n",
                "\n",
                "As we learnt in lecture, one way to vectorize text is using the [Term Frequency Inverse Document Frequency](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) (TF-IDF) featurizer. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vectorizer = TfidfVectorizer(max_df =0.95, min_df = 3, stop_words = 'english')\n",
                "X = vectorizer.fit_transform(data['Text'])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Print the shape of your dataset. **Question**: What does each dimension stand for?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "words = vectorizer.get_feature_names_out()words = vectorizer.get_feature_names_out()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Print the stop words. **Question**: Do you think this is a reasonable list of stopwords?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vectorizer.get_stop_words()vectorizer.get_stop_words()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 3. Running K-Means\n",
                "\n",
                "We will now run k-means to cluster the dataset, using sklearn's [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html). Set `random_state=416`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "k = 5\n",
                "kmeans = KMeans(n_clusters = k, random_state = 416)\n",
                "kmeans.fit(X)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "For visualization purposes, let's add the cluster labels to the pandas dataframe."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data[\"Clusters k=%d\" % k] = kmeans.labels_\n",
                "data"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Questions**: What trends do you observe? What underlying patterns might the clustering algorithm have picked up on?\n",
                "\n",
                "To further analyze the clusters, let's print the most frequent words per cluster."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cluster_to_words_to_num_occurences = {}\n",
                "for i in range(k):\n",
                "    cluster_to_words_to_num_occurences[i] = {}\n",
                "    for word in words:\n",
                "        num_occurences = 0\n",
                "        for _, text in data[(data[\"Clusters k=%d\" % k] == i)][\"Text\"].iteritems():\n",
                "            if word.lower() in text.lower().split(\" \"):\n",
                "                num_occurences += 1\n",
                "        cluster_to_words_to_num_occurences[i][word] = num_occurences\n",
                "\n",
                "num_words = 10\n",
                "for i in range(k):\n",
                "    top_words = [(cluster_to_words_to_num_occurences[i][word], word) for word in cluster_to_words_to_num_occurences[i]]\n",
                "    top_words.sort(reverse=True)\n",
                "    print(\"Cluster %d: \" % i, top_words[:num_words])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question**: What words are common across all clusters? What words are more unique to particular clusters?\n",
                "\n",
                "**Question**: Why do the clusters not correspond to meaningful topics of words?"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 4. Selecting K"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Sklearn's KMeans classifier's `inertia_` property returns the objective function, or quality, of the clustering. \n",
                "\n",
                "**Question**: What would we expect the inertia to be when k=59?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ks = []\n",
                "inertias = []\n",
                "for k in range(1, 60, 2):\n",
                "    # TODO: train a classifier with this k compute its quality\n",
                "    ks.append(k)\n",
                "    kmeans = KMeans(n_clusters = k).fit(X)\n",
                "    inertias.append(kmeans.inertia_)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Graph it out"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, ax = plt.subplots(figsize=(10, 5))\n",
                "ax.plot(ks, inertias, marker='o')\n",
                "ax.set_ylim(0, 50)\n",
                "ax.set_xlabel(\"K\")\n",
                "ax.set_ylabel(\"Objective Function\")\n",
                "ax.set_xticks(range(0, ks[-1], 2), minor=True)\n",
                "ax.grid(which='both')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question**: What appears to be the best value of k?\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 5. (Bonus) Exploring the Data!"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The below function takes in a list of words and graphs their occurance in presidents' speeches over the years. Use it to identify trends in the data!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def words_over_time(words):\n",
                "    cfd = ConditionalFreqDist(\n",
                "        (target, int(fileid[:4]))\n",
                "        for fileid in inaugural.fileids()\n",
                "        for w in inaugural.words(fileid)\n",
                "        for target in words\n",
                "        if w.lower().startswith(target))\n",
                "    cfd.plot()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(12, 5))\n",
                "words_over_time([\"war\", \"peace\"])"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        },
        "vscode": {
            "interpreter": {
                "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
