{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztkFDmv7go3K"
   },
   "source": [
    "<h1><center>STAT/CSE 416 Section 5: Precision and Recall, Random Forests, Ensemble Methods</center></h1>\n",
    "<center><b>Section:</b>AA/AB BA/BB</center>\n",
    "<center><b>Instructor:</b>Emilija PerkoviÄ‡</center>\n",
    "<center><b>TA:</b>Octavian-Vlad Murad</center>\n",
    "<center><b>Date:</b>February 9, 2023</center>\n",
    "\n",
    "*Author: Anne Wagner. Modifications: Octavian-Vlad Murad*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# University of Wisconsin Breast Cancer Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-WF3m37igoOD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vk73u17GhF_X"
   },
   "source": [
    "We have talked a bit about precision and recall, different types of classification error, and when certain types of error might be preferred. To help motivate this with an example, we will consider data on breast cancer scans by the University of Wisconsin.\n",
    "\n",
    "Data Source: UCI Machine Learning Repository http://archive.ics.uci.edu/ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJ0NJSaw_kff"
   },
   "source": [
    "The data we will be looking at consists of different metrics gathered from breast cancer biopsies. In total there are 10 different metrics gathered about the biopsied cells, repeated on 3 perpendicular axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer # load dataset \n",
    "dataset = load_breast_cancer() # returns a dictionary\n",
    "\n",
    "print(\"Target names:\", dataset.target_names)\n",
    "print(\"Feature names:\", dataset.feature_names)\n",
    "\n",
    "X_columns = list(dataset.feature_names)\n",
    "\n",
    "pd_dataset = pd.DataFrame(dataset.data, columns=list(dataset.feature_names))\n",
    "pd_dataset[\"cancer type\"] = -((dataset.target - 0.5) * 2).astype(int) # transform 0, 1 labels to -1, 1 labels. Flip labels because malignant is 0.\n",
    "\n",
    "pd_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this exercise, we are going to focus on just two of the variables: <i>perimeter error</i> and <i>worst texture</i>, chosen to help visualize examples. Note that we are not going to be using pd.Dataframe objects, but numpy arrays. This is no reason to worry because sklearn works with both just as fine. Furthermore, a pd.Dataframe object is pretty much a numpy array(the data in the table) + a bunch of features useful for data analysis that can manipulate that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gyUU5ajDbOsl"
   },
   "outputs": [],
   "source": [
    "# transform the data to numpy\n",
    "y = pd_dataset[\"cancer type\"].to_numpy()\n",
    "X = pd_dataset[[\"perimeter error\", \"worst texture\"]].to_numpy()\n",
    "\n",
    "# generate some random indices and split the data into train/test data at the mid point\n",
    "n = y.shape[0]\n",
    "inds = np.arange(n)\n",
    "np.random.RandomState(416)\n",
    "np.random.shuffle(inds)\n",
    "train_idx, test_idx = inds[:(n//2)], inds[(n//2):]\n",
    "\n",
    "X_train, y_train = X[train_idx], y[train_idx]\n",
    "X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "# boolean array of which samples are positives.\n",
    "mal = (y == 1)\n",
    "mal_test = (y_test == 1)\n",
    "mal_train = (y_train == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8bfz72oCRi_"
   },
   "source": [
    "Again for the purposes visualization, we are going to convert the data to a log scale. This will have no effect on the classification via decision trees (and related methods). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.log(X)\n",
    "X_train = np.log(X_train)\n",
    "X_test = np.log(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "- Why would using the log of the features have no effect on the classification when using decision trees?\n",
    "- Which other types of transformations could we apply to the data(i.e. what property should the transormations have to preserve the classification of a decision tree)?\n",
    "\n",
    "### Answer:\n",
    "- Decision trees only branch on a single variable at a time and the logarithm function is one-to-one. A branch at $x<a$ is identical to a branch at $log(x)<log(a)$ .\n",
    "- The transformations should be one-to-one or equivalently strictly monotonous(increasing or decreasing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now visualize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mLauNlbI5_Z0"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(16, 7.5), dpi=80)\n",
    "\n",
    "axs[0].set_title(\"Raw Data\")\n",
    "axs[0].set_xlabel(\"perimeter error\")\n",
    "axs[0].set_ylabel(\"worst texture\")\n",
    "axs[0].scatter(np.exp(X[mal, 0]),np.exp(X[mal, 1]),marker='+',cmap=\"blue\")\n",
    "axs[0].scatter(np.exp(X[~mal, 0]),np.exp(X[~mal, 1]),marker='_',cmap=\"red\")\n",
    "\n",
    "axs[1].set_title(\"Log Transformed Data\")\n",
    "axs[1].set_xlabel(\"log perimeter error\")\n",
    "axs[1].set_ylabel(\"log worst texture\")\n",
    "axs[1].scatter(X[mal, 0], X[mal, 1],marker='+',cmap=\"blue\")\n",
    "axs[1].scatter(X[~mal, 0], X[~mal, 1],marker='_',cmap=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically our goal in classification to try and accurately classify all classes. That is, we are usually interested in measuring the accuracy:\n",
    "\n",
    "$$Accuracy = \\frac{\\#\\text{ Correct Predictions}}{\\#\\text{ Data Points}}$$\n",
    "\n",
    "\n",
    "But in this particular context it is important to consider the two types of errors separately:\n",
    "\n",
    "$$\\text{Type 1 Error /}  \\text{ False Positive} = \\text{model predicts True while the actual label is False} $$\n",
    "$$\\text{Type 2 Error /}  \\text{ False Negative} = \\text{model predicts False while the actual label is True} $$\n",
    "\n",
    "### Question 2:\n",
    "- In the context of cancer biopsies, what does each type of error mean?\n",
    "- Which type of error do we care about more?\n",
    "\n",
    "### Answer:\n",
    "- A false positive means a patient who doesn't have a malignant tumor is being told that the test results were malignant. In this context, a false positive will likely result in the patient seeking more tests to confirm before starting any treatment. This is not an ideal outcome, but we are more concerned with...\n",
    "- A false negative means a patient who does have breast cancer is being told that the test results were benign. This may lead to the patient ignoring the problem until it becomes worse or entirely untreatable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48u1M7CJDYy4"
   },
   "source": [
    "Precision and recall both relate to the number of true positive observations, but calculate two different rates. \n",
    "\n",
    "<b>Precision:</b> refers to the ability to ensure positives predictions are truly positive. With an algorithm that is very precise, you can be assured that most positive predictions are actually positive.\n",
    "\n",
    "$$Precision = \\frac{\\#\\text{ True Positives}}{\\#\\text{ True Positives} + \\#\\text{ False Positives}}$$\n",
    "\n",
    "<b>Recall:</b> refers to the ability to ensure that cases that are positive are predicted positively. With an algorithm with high recall, you can be assured that you will predict most positive cases correctly.\n",
    "\n",
    "$$Recall = \\frac{\\#\\text{ True Positives}}{\\#\\text{ True Positives} + \\#\\text{ False Negatives}}$$\n",
    "\n",
    "### Question 3:\n",
    "- In the context of this data set, which are we more concerned with, and why? \n",
    "- Can we create a predictor that scores perfectly on that metric while still being useless?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_q5bSDfZFPsu"
   },
   "source": [
    "### Answer \n",
    "- We care more about our model having a high recall. That way we can ensure that anyone who does have breast cancer is properly informed. \n",
    "- At the same time, we could just classify every case as malignant and achieve a recall of 1, but there is literally no point in taking that test as it offers no value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsOUllZZFTBD"
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfLuhYrgFrpU"
   },
   "source": [
    "Let's look at a simple decision tree on this data. We will use a tree of depth of 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtm = DecisionTreeClassifier(max_depth=6, random_state=1)\n",
    "dtm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now visualize the confusion matrix for how our model classifies our train data. First some boiler-plate code for visualizing the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix as cm\n",
    "\n",
    "def plot_confusion_matrix(model, X, y_true, threshold=None):\n",
    "    \n",
    "  if threshold is None:\n",
    "    y_pred = model.predict(X)\n",
    "  else:\n",
    "    y_pred = ((model.predict_proba(X)[:, 1] >= threshold) - .5) * 2 # transforming probabilities to -1 and 1.\n",
    "    \n",
    "  cm_data = cm(y_true, y_pred)\n",
    "  cm_data = cm_data.ravel()[::-1].reshape(cm_data.shape)\n",
    "  plt.figure(figsize=(8, 8), dpi=80)\n",
    "  sns.heatmap(cm_data, annot=True, fmt=\".0f\", xticklabels=['Pred True', 'Pred False'],\n",
    "              yticklabels = ['Actual True', 'Actual False'])\n",
    "  return cm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hUuPMLCt5bVG"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "\n",
    "dtm = DecisionTreeClassifier(max_depth=6, random_state=1)\n",
    "dtm.fit(X_train, y_train)\n",
    "\n",
    "cm_data = plot_confusion_matrix(dtm, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNcuwqUHEDiU"
   },
   "source": [
    "### Question 4:\n",
    "- Take a moment to try and calculate the precision and recall for this training data.\n",
    "\n",
    "### Answer:\n",
    "- Run code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zu1uwwZ8G72B"
   },
   "outputs": [],
   "source": [
    "def print_prec_and_recall(cm_data):\n",
    "  #We can quickly calculate the precision and recall from the confusion matrix\n",
    "  print(\"Precision: \",np.round(cm_data[0, 0]/(cm_data[0, 0]+cm_data[1, 0]),5))\n",
    "  print(\"Recall:\", np.round(cm_data[0, 0]/(cm_data[0, 0]+cm_data[0, 1]),5))\n",
    "print_prec_and_recall(cm_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now visualise our the classifier's predictions on the train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, X, y_true, pos_vec, title, threshold=None, stages=None, size=None):\n",
    "    \n",
    "    if stages is not None:\n",
    "        y_pred = [((yp[:, 1] >= .5) - .5) * 2  if yp.ndim == 2 else yp\n",
    "                  for i, yp in enumerate(model.staged_predict_proba(X)) if i in stages]\n",
    "    elif threshold is not None:\n",
    "        y_pred = ((model.predict_proba(X)[:, 1] >= threshold) - .5) * 2 # transforming probabilities to -1 and 1.\n",
    "    else:\n",
    "        y_pred = model.predict(X)\n",
    "    \n",
    "    if stages is not None:\n",
    "        correct_vec = [y_true==yp for yp in y_pred]\n",
    "    else:\n",
    "        correct_vec = y_true==y_pred\n",
    "    \n",
    "    grid=np.meshgrid(np.arange(-.5,3.2,.008),np.arange(2.4,4.0,.008))\n",
    "    grid=np.stack([grid[0].flatten(),grid[1].flatten()], axis=1)\n",
    "\n",
    "    norm = colors.Normalize(vmin=-1, vmax=1)\n",
    "    \n",
    "    if stages is not None:\n",
    "        grid_colors = [plt.cm.seismic(norm((gp[:, 1]-.5)*(-2))) if gp.ndim == 2 else plt.cm.seismic(norm(gp))\n",
    "                       for i, gp in enumerate(model.staged_predict_proba(grid)) if i in stages]\n",
    "    else:\n",
    "        probs = model.predict_proba(grid)\n",
    "        if probs.ndim == 2:\n",
    "            probs = probs[:, 1]\n",
    "            grid_colors = plt.cm.seismic(norm((probs-.5)*(-2)))\n",
    "        else:\n",
    "            grid_colors = plt.cm.seismic(norm(probs))\n",
    "    \n",
    "\n",
    "    if size is None:\n",
    "        size = 200\n",
    "        \n",
    "    if stages is not None:\n",
    "        \n",
    "        fig, axs = plt.subplots(len(stages)//2, 2, figsize=(16, 7.5 * (len(stages)//2)), dpi=80)\n",
    "        \n",
    "        if type(size) == int:\n",
    "            size_c, size_ic = len(stages) * [size//4], len(stages) * [size]\n",
    "        else:\n",
    "            size_c, size_ic = size.copy(), size.copy()\n",
    "        \n",
    "        for i, (stage, cv, gc, s_c, s_ic) in enumerate(zip(stages, correct_vec, grid_colors, size_c, size_ic)):\n",
    "            \n",
    "            i, j = i//2, i%2\n",
    "            axs[i, j].set_title(\"AdaBoost stage \" + str(stage))\n",
    "            axs[i, j].set_xlabel(\"perimeter error\")\n",
    "            axs[i, j].set_ylabel(\"worst texture\")\n",
    "            \n",
    "            axs[i, j].scatter(grid[:, 0],grid[:, 1], marker='.',c=gc, alpha=.25)\n",
    "            \n",
    "            if type(s_c) == int:\n",
    "                \n",
    "                axs[i, j].scatter(X[pos_vec & cv, 0], X[pos_vec & cv, 1], s=s_c, marker='+',c='cyan', alpha=.6)\n",
    "                axs[i, j].scatter(X[~pos_vec & cv, 0], X[~pos_vec & cv, 1], s=s_c, marker='_',c=\"orange\", alpha=.6)\n",
    "                axs[i, j].scatter(X[pos_vec & ~cv, 0], X[pos_vec & ~cv, 1], s=s_ic, marker='+',c='cyan')\n",
    "                axs[i, j].scatter(X[~pos_vec & ~cv, 0], X[~pos_vec & ~cv, 1], s=s_ic, marker='_',c='orange')\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                axs[i, j].scatter(X[pos_vec & cv, 0], X[pos_vec & cv, 1], s=s_c[pos_vec & cv], marker='+',c='cyan', alpha=.6)\n",
    "                axs[i, j].scatter(X[~pos_vec & cv, 0], X[~pos_vec & cv, 1], s=s_c[~pos_vec & cv], marker='_',c=\"orange\", alpha=.6)\n",
    "                axs[i, j].scatter(X[pos_vec & ~cv, 0], X[pos_vec & ~cv, 1], s=s_ic[pos_vec & ~cv], marker='+',c='cyan')\n",
    "                axs[i, j].scatter(X[~pos_vec & ~cv, 0], X[~pos_vec & ~cv, 1], s=s_ic[~pos_vec & ~cv], marker='_',c='orange')\n",
    "\n",
    "    else:\n",
    "        plt.figure(figsize=(8, 8), dpi=80)\n",
    "    \n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"log perimeter error\")\n",
    "        plt.ylabel(\"log worst texture\")\n",
    "    \n",
    "        plt.scatter(grid[:, 0],grid[:, 1], marker='.',c=grid_colors, alpha=.25)\n",
    "        plt.scatter(X[pos_vec & correct_vec, 0], X[pos_vec & correct_vec, 1], marker='+',c='cyan', alpha=.6)\n",
    "        plt.scatter(X[~pos_vec & correct_vec, 0], X[~pos_vec & correct_vec, 1], marker='_',c=\"orange\", alpha=.6)\n",
    "        plt.scatter(X[pos_vec & ~correct_vec, 0], X[pos_vec & ~correct_vec, 1], s=size, marker='+',c='cyan')\n",
    "        plt.scatter(X[~pos_vec & ~correct_vec, 0], X[~pos_vec & ~correct_vec, 1], s=size, marker='_',c='orange')\n",
    "    \n",
    "visualize_predictions(dtm, X_train, y_train, mal_train, title=\"Train Data Classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5:\n",
    "- Do you see any evidence that the model is overfitting?\n",
    "- We can see from the color coding that different regions are colored differently. We do this to convey that the classifier has different confidences in its predictions for different regions. What does each region correspond to and how are these confidences computed?\n",
    "\n",
    "### Answer:\n",
    "- The very thin lines which classify one or two points that are deep into the regions corresponding to the other label are indications of overfitting.\n",
    "- Each region corresponds to a leaf(terminal node) in the tree. At each leaf, we will have $N_{neg}$ negative training data points and $N_{pos}$ positive training data points. The model computes $p_{neg} = \\frac{N_{neg}}{N_{neg} + N_{pos}}$, the probability that points in the region are negative, and $p_{pos} = 1 - p_{neg}$, the probability that the points in the region are positive. Thus, the confidence is how close the greater of the two probabilities is to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eHd9iXNaMCzS"
   },
   "outputs": [],
   "source": [
    "cm_data = plot_confusion_matrix(dtm, X_test, y_test)\n",
    "print_prec_and_recall(cm_data)\n",
    "visualize_predictions(dtm, X_test, y_test, mal_test, title=\"Test Data Classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Kqm91mlfDCC"
   },
   "source": [
    "We can see here that the precision and recall are considerably lower, which is an indication that we are likely overfitting.\n",
    "\n",
    "### Question 6:\n",
    "- Maintaining this model, is there a way we can improve the recall? If we can, what effect will this have on the precision?\n",
    "\n",
    "### Answer:\n",
    "- We can change the threshold that we use to classify points as positive. This will improve recall, but will lower precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j9MzHB8Phobt"
   },
   "outputs": [],
   "source": [
    "#IE: we will classify as malignant if more than 20% of points on a leaf are malignant\n",
    "cm_data = plot_confusion_matrix(dtm, X_test, y_test, threshold=0.20)\n",
    "print_prec_and_recall(cm_data)\n",
    "visualize_predictions(dtm, X_test, y_test, mal_test, title=\"Test Data Classification with 0.2 threshold\", threshold=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSmgUU2-MCXr"
   },
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxL99rtEOzxz"
   },
   "source": [
    "AdaBoost is founded on the <i>boosting</i> principle: the idea that we can build a strong classifier by combining a bunch of weak classifiers(also called base classifiers). The AdaBoost algorithm relies on decision stumps(trees that only consist of the root) as the base classifiers. The decision stumps are added sequentially to the main classifier and weighted according to their accuracy. The algorithm proceeds as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14dJo0fEO1PS"
   },
   "source": [
    "Suppose we are given a data set $\\mathcal{D} = \\{(x_1, y_1), \\dots, (x_n, y_n)\\}$.\n",
    "\n",
    "Initialization:\n",
    "* Assign each point a *data weight* $\\alpha_i=\\frac{1}{n}$.\n",
    "\n",
    "for $t$ in $[1,2,...,T]$:\n",
    "* Learn a decision stump $\\hat f_t(x)$. That is, find the best feature(and potentially the best split point for continuous features) to split the data on. By the \"best\", we mean the feature(and potentially the split point) which minimizes the $WeightedError$ below. \n",
    "* Calculate the $WeightedError$ for the learned decision stump $\\hat f_t(x)$.\n",
    "\n",
    "$$WeightedError = \\frac{\\sum_{i=1}^n \\alpha_i I(\\hat f_t(x_i) \\neq y_i)}{\\sum_{i=1}^n\\alpha_i}$$\n",
    "\n",
    "*   Set the *model weight* according to the weighted error\n",
    "$$\\hat{w}_t=\\frac{1}{2}ln\\left(\\frac{1-WeightedError(\\hat{f}_t)}{WeightedError(\\hat{f}_t)}\\right)$$\n",
    "\n",
    "* Update the *data weights* $\\alpha_i$, shrinking the weight corresponding to correctly classified points and raising it for the points that were incorrectly classified. Note that $-y_if_t(x_i) = -1$ if the prediction is correct and $-y_if_t(x_i) = 1$ otherwise.\n",
    "$$\\alpha_i=\\alpha_ie^{-y_if_t(x_i)\\hat{w}_t}$$\n",
    "\n",
    "- To avoid the weights becoming too extreme and causing numerical issues with computation, we can normalized the $\\alpha_i$'s at each step $t$.\n",
    "\n",
    "To make predictions we use the final model:\n",
    "\n",
    "$$\\hat{y}=\\hat{F}(x)=sign\\left(\\sum_{t=1}^T\\hat{w}_t\\hat{f}_t(x)\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohAUyPGarSgu"
   },
   "source": [
    "Because the AdaBoost algorithm doesn't let you see things like *data weights* as the model is fitting, I wrote my own. Let's work through the code together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CdVv0-WcBp0l"
   },
   "outputs": [],
   "source": [
    "class AdaBoostManual:\n",
    "  def __init__(self, num_trees, X, y):\n",
    "    \n",
    "    self.stumps=[DecisionTreeClassifier(max_depth=1,random_state=i) for i in range(num_trees)]\n",
    "    self.data_weights=np.zeros((num_trees,X.shape[0]))\n",
    "    self.model_weights=np.zeros(num_trees)\n",
    "    \n",
    "    self.X = X\n",
    "    self.y = y\n",
    "    self.num_trees=num_trees\n",
    "    self.stump_predictions=np.zeros((num_trees,X.shape[0]))\n",
    "    self.predictions=np.zeros((num_trees,X.shape[0]))\n",
    "    self.psuedoprob=np.zeros((num_trees,X.shape[0]))\n",
    "    \n",
    "    #I just like to save lots of stuff in case I want to use it later.\n",
    "\n",
    "  def train(self):\n",
    "    \n",
    "    #Initialize for the first tree - data weights are equal.\n",
    "    self.data_weights[0]= 1 / self.X.shape[0]\n",
    "    \n",
    "    #The decision stump is fit and a number of variables are saved\n",
    "    self.stumps[0].fit(self.X,self.y)\n",
    "    self.stump_predictions[0]=self.stumps[0].predict(self.X)\n",
    "    \n",
    "    #We calculate the errors for this model(+1 if there is no error, -1 if there is an error)\n",
    "    errors = self.stump_predictions[0] * self.y\n",
    "    #Which we use to calculate the weighted error (unweighted for the first stump)\n",
    "    WeightedError=np.sum(errors == -1)/self.X.shape[0]\n",
    "    #We assign the model weight according to the weighted error\n",
    "    self.model_weights[0]=0.5*np.log((1-WeightedError)/WeightedError)\n",
    "    \n",
    "    #We use the errors to adjust the weights\n",
    "    self.data_weights[0]= self.data_weights[0] * np.exp(-errors*self.model_weights[0])\n",
    "    \n",
    "    #Lastly, we normalize\n",
    "    self.data_weights[0]=self.data_weights[0]/self.data_weights[0].sum()\n",
    "    \n",
    "    # compute the predictions\n",
    "    self.predictions[0] = self.model_weights[0] * self.stump_predictions[0]\n",
    "    self.psuedoprob[0] = self.predictions[0]/np.max(np.abs(self.predictions[0]))\n",
    "    \n",
    "    for i in range(1,self.num_trees):\n",
    "      \n",
    "      self.stumps[i].fit(self.X,self.y,sample_weight=self.data_weights[i-1])\n",
    "      self.stump_predictions[i] = self.stumps[i].predict(self.X)\n",
    "    \n",
    "      #We take the sign of the resulting sum as the predicted value\n",
    "      errors=self.stump_predictions[i] * self.y\n",
    "      #Which we use to calculate the weighted error (unweighted for the first stump)\n",
    "      WeightedError= np.sum(self.data_weights[i-1] * (errors == -1))/self.data_weights[i-1].sum()\n",
    "      #Then we again assign the model weight and update data weights\n",
    "      self.model_weights[i]=0.5*np.log((1-WeightedError)/WeightedError)\n",
    "    \n",
    "      #We use the errors to adjust the weights\n",
    "      self.data_weights[i]=self.data_weights[i-1]*np.exp(-errors*self.model_weights[i])\n",
    "    \n",
    "      #Lastly, we normalize\n",
    "      self.data_weights[i]=self.data_weights[i]/self.data_weights[i].sum()\n",
    "        \n",
    "      # compute the predictions\n",
    "      self.predictions[i] = self.predictions[i - 1] + self.model_weights[i] * self.stump_predictions[i]\n",
    "      self.psuedoprob[i] = self.predictions[i]/np.max(np.abs(self.predictions[i]))\n",
    "\n",
    "  def predict(self,X,early_stop=None):\n",
    "    \n",
    "    preds=np.zeros(X.shape[0])\n",
    "    if early_stop is None:\n",
    "      for i in range(self.num_trees):\n",
    "        tmp=self.stumps[i].predict(X)\n",
    "        preds=preds+tmp*self.model_weights[i]\n",
    "    else:\n",
    "      for i in range(early_stop):\n",
    "        tmp=self.stumps[i].predict(X)\n",
    "        preds=preds+tmp*self.model_weights[i]\n",
    "    preds=np.sign(preds)\n",
    "    return(preds)\n",
    "\n",
    "  def staged_predict_proba(self, X):\n",
    "        preds=np.zeros((self.num_trees, X.shape[0]))\n",
    "        for i in range(self.num_trees):\n",
    "            tmp=self.stumps[i].predict(X)\n",
    "            if i == 0:\n",
    "                preds[i]= tmp * self.model_weights[i]\n",
    "            else:\n",
    "                preds[i]= preds[i-1] + tmp*self.model_weights[i]\n",
    "        preds=preds/np.max(np.abs(preds))\n",
    "        return(-preds)\n",
    "        \n",
    "  #This is not a true probability, but instead returns a value between -1 and 1.\n",
    "  def predict_proba(self,X,early_stop=None):\n",
    "    preds=np.zeros(X.shape[0])\n",
    "    if early_stop is None:\n",
    "      for i in range(self.num_trees):\n",
    "        tmp=self.stumps[i].predict(X)\n",
    "        preds=preds+tmp*self.model_weights[i]\n",
    "    else:\n",
    "      for i in range(early_stop):\n",
    "        tmp=self.stumps[i].predict(X)\n",
    "        preds=preds+tmp*self.model_weights[i]\n",
    "    preds=preds/np.max(np.abs(preds))\n",
    "    return(-preds)\n",
    "\n",
    "ABE=AdaBoostManual(48, X_train, y_train)\n",
    "ABE.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well our model is doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cm_data = plot_confusion_matrix(ABE, X_test, y_test)\n",
    "print_prec_and_recall(cm_data)\n",
    "visualize_predictions(ABE, X_test, y_test, mal_test, title=\"Test Data Classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9RDTSPE33wp"
   },
   "source": [
    "Let's look at how weights are changing from run to run\n",
    "\n",
    "The plots below show how the points are being classified after the first $k$ trees. The size of a point is proportional to the weight of the point after the $k$th tree, with the incorrectly classified points emphasized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = ABE.data_weights\n",
    "size = (size - np.min(size))/(np.max(size) - np.min(size))\n",
    "visualize_predictions(ABE, X_train, y_train, mal_train, title=\"Train Data Classification\", stages=range(0, 48, 6), size=size * 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LF0aVCDsucK"
   },
   "source": [
    "The *sklearn* library of course has its own AdaBoost algorithm, capable of either classification or regression. Much easier than writing your own, though it does not give quick and easy access to some of the parameters (such as the model or data weights). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eR0ck5uccBwT"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "abc=AdaBoostClassifier(n_estimators=48, random_state=1)\n",
    "abc.fit(X_train, y_train)\n",
    "\n",
    "cm_data = plot_confusion_matrix(abc, X_train, y_train)\n",
    "print_prec_and_recall(cm_data)\n",
    "visualize_predictions(abc, X_train, y_train, mal_train, title=\"Train Data Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wls2dYeyz168"
   },
   "outputs": [],
   "source": [
    "#testing data\n",
    "cm_data = plot_confusion_matrix(abc, X_test, y_test)\n",
    "print_prec_and_recall(cm_data)\n",
    "visualize_predictions(abc, X_test, y_test, mal_test, title=\"Test Data Classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkkTlJnatsrV"
   },
   "source": [
    "We can even look at the stagewise predictions for only the first $k$ models, but the access is somewhat clunky. Below is the 10th model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FYWJun6AZ17n"
   },
   "outputs": [],
   "source": [
    "visualize_predictions(abc, X_train, y_train, mal_train, title=\"Train Data Classification\", stages=range(0, 48, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KS2aeyR6uxzF"
   },
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFEbe-7pvQHd"
   },
   "source": [
    "Random Forests attempt to improve upon using a single Decision Tree. The RF algorithm does so by training an ensemble of trees via Bootstrapping. The RF then uses each trained tree to cast a voter and the majority decision will represent the classifier's decision.\n",
    "\n",
    "To produce a variety of trees from a single data set, we use BootStrapping which consists of sampling multiple new training data sets from the original data set and training a tree for each of these. Furthermore, by randomly selecting a subset of all the features on which to construct the trees, we further increase the variety of trees which we train. This helps considerably with reducing the variance inherent to training a single Decision Tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7cga4FgvQe5"
   },
   "source": [
    "##### Random Forrest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1FRlUCSvSoA"
   },
   "source": [
    "<img src=\"https://occ-0-2794-2219.1.nflxso.net/dnm/api/v6/E8vDc_W8CLv7-yMQu8KMEC7Rrr8/AAAABRH4YM-SODj1fGal_ylc15ebTe90p_j_WPiMUjXpRGFZqMdCtc7zSFJe9C2OliUhCGmyu0APQWKZ3Q6CzAGSA8_D26Sj.jpg\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHS97QsozBxn"
   },
   "source": [
    "Let us now see how we can train a Random Forest in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g68UYA-BzKH8"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc=RandomForestClassifier(n_estimators=50, random_state=1, max_depth=6)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "cm_data = plot_confusion_matrix(rfc, X_train, y_train)\n",
    "print_prec_and_recall(cm_data)\n",
    "visualize_predictions(rfc, X_train, y_train, mal_train, title=\"Train Data Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tsfw5XQy1HnS"
   },
   "outputs": [],
   "source": [
    "#Test data\n",
    "cm_data = plot_confusion_matrix(rfc, X_test, y_test)\n",
    "print_prec_and_recall(cm_data)\n",
    "visualize_predictions(rfc, X_test, y_test, mal_test, title=\"Test Data Classification\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ztkFDmv7go3K",
    "PJ0NJSaw_kff",
    "keJ2jRIMsukf",
    "9CdzdV2js87V",
    "sGWwMI5bHBNo",
    "_q5bSDfZFPsu",
    "xsOUllZZFTBD",
    "xPojVh65hmgi",
    "SSmgUU2-MCXr",
    "sqMLxhPo3zHn",
    "S9RDTSPE33wp",
    "KS2aeyR6uxzF",
    "L7cga4FgvQe5",
    "jHS97QsozBxn",
    "_qr_RH0W-ptQ"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ff228adae71f8b16dd2174beedd5314406215b14462e82025a7eeccf1226a0f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
